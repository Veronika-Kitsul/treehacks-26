None selected 

Skip to content
Using Princeton University Google Apps Mail with screen readers
treehacks 

Conversations
[Important] TreeHacks 2026 Logistics
Inbox

TreeHacks <hello@treehacks.com>
Tue, Feb 10, 9:43‚ÄØPM (2 days ago)
to me

VIEW THIS EMAIL IN BROWSER

 
 



TreeHacks 2026


final logistics guide
Hackers! We are only 3 days away from TreeHacks 2026, and we are so excited to see you all soon!



Some highlights:

Announcing over $500,000 in prizes this year!

Opening ceremony with Sam Altman and Garry Tan.



This is the final logistics email you will receive from us‚Äîplease make sure you read through this email in its entirety so you do not miss any important information that will prevent you from participating in TreeHacks 2026!

Prizes announced

Devpost

Qualifications

Track/sponsor prizes

Important logistics

Badges

Opening Ceremony

Check-in Location

Must brings

Slack

Ultimate Guide

Final Event Schedule

TreeHacks Live

Transportation

Parking

Train hackers



If you have any questions, please put them in #ask-an-organizer in Slack. Only email us if your inquiry is personal! See you all soon!

 
Prizes Announced!

We‚Äôre super excited to announce that TreeHacks 2026 will feature our largest prize pool ever of over $500,000!



We will hand out prizes in the following categories:



Grand Prize (1st, 2nd, 3rd place)

Most Technically Complex

Most Creative Hack

Best Hardware Hack

Most Impactful Hack

Best Beginner Hack

AI Grand Prize

Cloud AI Grand Prize

Edge AI Grand Prize

Inference Grand Prize

Sustainability Grand Prize

Education Grand Prize

Healthcare Grand Prize

Human Flourishing Grand Prize

YC x Treehacks Challenge



On top of this, there are 25+ additional sponsor challenges and prizes which can be found in our prize list!





Devpost



Devpost will be released Friday Feb. 14th. We will send it in #announcement on Slack once it is out!



To qualify for prizes:

All members of your team must have checked-in to TreeHacks and have your TreeHacks badge



At least one member of your team must be physically present to demo your project to judges on Sunday (check schedule for specific time)



All building must have taken place during hacking hours (9:30pm on Friday, Feb. 13 - 9:30am on Sunday, Feb. 15)



Note: ideation and planning is allowed (and encouraged) before the hackathon, but all coding/building must take place during hacking hours.



Hackers can only start hacking after checking-in. If your teammate is arriving late, they are not allowed to start coding before they check-in.



We check ALL GitHub commits before we announce prizes!

2026 Prize List
Important Logistics

Personalized Badge

Each hacker will receive a personalized badge this year with your name and a personal QR code on the back. You must wear this at all times. There will be TreeHacks organizers and police officers walking around to ensure that everyone has their badge, and you will be asked to leave our buildings if you do not have a badge. You will also need the QR code on your badge to get meals.

Each hacker only receives 1 badge, and there‚Äôs no replacements if lost. Please do not lose your badge and keep it on you at all times until you depart on Sunday, even when you‚Äôre resting/eating.



Opening Ceremony Logistics

We are so excited to have Sam Altman and Garry Tan as our opening ceremony speakers this year! The opening ceremony will be exclusive to TreeHacks hackers only ‚Äî no outside/unregistered participants are allowed to attend.

The opening ceremony will take place at Memorial Auditorium (MemAud), which is a 10 minute walk from Huang Engineering Center.

You must have a badge to attend Opening Ceremony. You must pick up your badge at Huang Engineering Center during check in.

For security reasons, there will be no bringing bags into the venue at all.

We recommend leaving bags in Huang Engineering Center. While we cannot guarantee the security of your bags and are not responsible for lost bags, our team and hired security is on site at all times.



Hacking Location

TreeHacks 12 will take place February 13 - 15, 2026 in the Jen-Hsun Huang Engineering Center (‚ÄúHuang‚Äù) at 475 Via Ortega, Stanford, CA 94305 and David Packard Electrical Engineering Building (‚ÄúPackard‚Äù) at 350 Serra Mall, Stanford, CA 94305.

To provide more working spaces for hackers, we are renting out the first floor of Packard. We set up 200 chairs with tables and power cords in Packard, as well as ethernet cables and power cords! If you need a place to work, Packard will be available starting after opening ceremony on Friday.

The two buildings are near each other in the Stanford Engineering Quad.



Check-in Location

Check-in takes place at Huang. At registration, you will be required to present:

a valid school ID

a valid government ID (passport or driver‚Äôs license)

We will not be able to let you compete if you are under 18 or do not attend an accredited university full-time. We won‚Äôt be taking any walk-in hackers this year!



Wi-Fi Password

The Wi-Fi password is "treehacks2026!" in both Huang and Packard.



What to Bring/Accommodations

Please try to pack light! We do not have bag check, and TreeHacks will not be responsible for any lost items! We have designated rest areas for our hackers, but we do not book or reimburse hotels if you plan on booking one!

Here‚Äôs the suggest packing list:

Valid school ID (mandatory)

Valid government ID, ie. passport or driver‚Äôs license (mandatory)

Sleeping bag

Sleeping mattress

Chargers

Laptop/electronic devices

Jacket/clothes for change

Umbrella in case of rain

TreeHacks will provide the following for hackers, but please feel free to bring your own in case we run out early!

Sleeping Masks

Toothbrush & toothpaste

Deodorant

Body Wipes

Reusable water bottle



Slack

Please join our slack! Many major announcements will be sent there from now on. Use any one of these links to join:

Slack Link #1

Slack Link #2

Slack Link #3

Slack Link #4





Flight Reimbursement

In order to have your flight reimbursed, you must attend the event and submit a quality project to our Devpost on time, alongside our other requirements outlined in our travel policy.

If you have an SSN, you must have submitted your tax information to payee.stanford.edu. In the days after filling it out, you should have received an email requesting you to submit your SSN. If you have not done both steps, you will be ineligible for reimbursement. We cannot check if you have done both steps on our end.

If you are an international student or do not have an SSN, we will reimburse you through a separate process after the event.

All reimbursements will be sent in the mail as a Check/Cheque to the address we have on file.

As the system is handled by the university, TreeHacks is unable to check if you have submitted your information or update any of the information you submitted in the past. We cannot update your address or reimburse you through a method other than a check.

We will process reimbursements in the months after the event!



Ultimate Guide

Here is the ‚ÄúUltimate Guide to TreeHacks 2026‚Äù that contains all sorts of information you need to know as a hacker, including final event schedule, prizes, etc. Please read it after you finish reading this email!

Ultimate Guide to TreeHacks 2026
 
Final Event Schedule

Find our final event schedule on Live, a web app that you can add to your home screen and enable push notifications on events that you subscribe to!



We encourage you to browse through all of our sponsor workshops, fun HackX events, and other offerings to curate your personal TreeHacks weekend via Live!

TreeHacks Live
 
Transportation

Parking

If you drove to Stanford, you can park your car at Via Ortega Lot or Roble Field Garage for free after 4pm on Friday!

You can find more information about parking on campus here.

TreeHacks will not be covering any parking expenses you may incur throughout the event.



Train Hackers

In your Trunk portal, if you are eligible for a Bart/Caltrain reimbursement, you must follow the following steps to get your ticket reimbursed.

You must purchase exact tickets, not Clipper Card fare.

You must depart from the station nearest to your University and arrive at Palo Alto Caltrain station.

Your receipt must include the breakdown of the cost of each item/ticket you purchased and the last 4 digits of your credit card/debit card number.

If you do not have an itemized receipt, you will not be able to be reimbursed.

The last 4 digits must be included on the receipt, no exceptions.

If your receipt does not fulfill these requirements, you will not be eligible for reimbursement per Stanford policies (edited)



After the event, please submit your reimbursement request here. Train reimbursements are due Feb 22nd, 2026.

 
 
Copyright (C) 2026 TreeHacks. All rights reserved. You are receiving this email because you opted in via our website.



Our mailing address is:

TreeHacks

520 Lasuen Mall

Stanford, CA 94305-3014

USA


Want to change how you receive these emails?

You can update your preferences or unsubscribe


...

[Message clipped]  View entire message

Veronika Kitsul <vk6976@princeton.edu>
‚óè
5:36‚ÄØPM (1 hour ago)
to maksym.d.bondarenko


treehacks 2026



if we want to build ai-based security and vulnerability scanner for github repos, do you think that's a very cool project and waht tracks can we possibly qualify for?

Yes ‚Äî that‚Äôs a very strong hackathon idea if you execute it sharply.

Given both of you:

Systems + networking + security background

ML + infra interests

Startup instincts

Veronika leaning toward systems / networking / security

You thinking about infrastructure-level AI

This is aligned.

Now let‚Äôs break it down strategically.

üî• Is it cool?

Yes ‚Äî if you avoid ‚Äúanother wrapper around static analysis.‚Äù

Not cool:

GPT that reads repo and says ‚Äúlooks insecure‚Äù

Regex-based vulnerability search

Just calling npm audit and summarizing

Cool:

AI that reasons across files

Detects architectural vulnerabilities

Understands authentication flows

Finds insecure trust boundaries

Detects secrets + dangerous patterns + infra misconfigs

Cross-repo attack surface modeling

Explains exploit chain step-by-step

Suggests minimal diff patch

Even cooler:

Combine static + LLM reasoning

Generate proof-of-concept exploit

Score exploitability, not just severity

Continuous scanning bot via GitHub App

That becomes real.

üèÜ What prizes you could target

Let‚Äôs go through TreeHacks categories:

1Ô∏è‚É£ AI Grand Prize

Very realistic if:

Core innovation is AI reasoning

Not just tool aggregation

You show intelligent exploit chain modeling

This is your strongest general category.

2Ô∏è‚É£ Cloud AI Grand Prize

If:

You deploy as scalable GitHub App

Use cloud inference

Real-time scanning

CI/CD integration

If infra is solid ‚Üí yes.

3Ô∏è‚É£ Edge AI Grand Prize

Not likely unless you:

Run model locally

Build on-device scanner

Show lightweight model optimized for edge

Probably not your best bet.

4Ô∏è‚É£ Inference Grand Prize

If you:

Optimize inference cost

Do smart chunking

Custom retrieval over repo

Caching embeddings

Fast scanning of large codebases

If you show systems-level efficiency ‚Üí strong.

Given your systems background, this could be powerful.

5Ô∏è‚É£ Most Technically Complex

Very viable.

If you:

Build full repo graph

Parse AST

Build call graph

Use LLM to reason over graph

Detect multi-step vulnerability chains

Judges love complexity if demo is clear.

6Ô∏è‚É£ Most Impactful Hack

Security tools are always impactful.

Frame it as:

‚ÄúEvery repo is a potential attack surface. We built an AI that reasons about vulnerabilities like a red-team engineer.‚Äù

That plays very well.

7Ô∏è‚É£ Best Hardware Hack

No.

8Ô∏è‚É£ YC x TreeHacks Challenge

Very viable.

YC LOVES:

Developer tools

GitHub integrations

Security infra

AI + infra

If you pitch it like:

‚ÄúAI-powered continuous security engineer for every startup.‚Äù

This fits YC vibes extremely well.

üéØ Strategic Track Targeting

Best realistic targets:

AI Grand Prize

Most Technically Complex

Most Impactful

YC Challenge

Inference Grand Prize

That‚Äôs already 5 possible categories.

üí° How to Make It Win-Worthy

To elevate it beyond ‚Äúanother AI tool‚Äù:

1Ô∏è‚É£ Don‚Äôt just detect vulnerabilities ‚Äî model exploit chains

Example:

File A ‚Üí unsafe deserialization

File B ‚Üí exposed endpoint

Missing auth layer

Chain leads to remote code execution

If your demo shows:

‚ÄúHere is the exploit path. Here is the patch diff.‚Äù

That‚Äôs elite.

2Ô∏è‚É£ Use structural understanding

Build:

Repo graph

Dependency graph

API surface map

Trust boundary detection

LLM reasons over graph.

That‚Äôs technically impressive.

3Ô∏è‚É£ Show live demo

Demo flow:

Paste GitHub repo

It scans

Generates:

Vulnerability list

Exploit chain

Risk score

Patch suggestion

Maybe auto-create PR

Judges LOVE visible action.

4Ô∏è‚É£ Add surprise factor

Examples:

‚ÄúRed-team mode‚Äù where it generates attack payload

‚ÄúDefense mode‚Äù where it rewrites code

Visual attack graph

Slack bot that alerts you

üß† Is it too common?

Security + AI is common.

But exploit-chain reasoning across full repo is not common.

Most tools:

Lint-level

Static pattern matching

CVE lookup

Secret scanning

Few tools reason semantically across files.

That‚Äôs your differentiation.

üèÅ Verdict

Yes, it‚Äôs a strong hackathon project.

It aligns with:

Systems

Security

AI

Infra

YC-style thinking

Real startup potential

If executed well, it can compete for:

AI Grand Prize

Most Technically Complex

YC challenge

Impact prize

If you want, next we can:

Design the minimal MVP architecture for 36 hours

Decide stack (Rust backend? Python? FastAPI?)

Design demo flow optimized for judges

Or brainstorm a sharper name + positioning

What direction do you want to take this?

these are all the prizes -- 
TreeHacks 2026 General Prizes
TreeHacks will have over $500,000 in prizes this year. Check them out below!

Note: Each team can apply for up to 10 prizes. All prizes are opt-in (you have to apply on your Devpost submission) except for the Grand Prize, Most Creative, Most Impactful, and Most Technically Complex (which everyone is eligible for and don‚Äôt count as part of the 10).

Sponsor
Name
Description
Prize
TreeHacks
TreeHacks Grand Prize 
First Place
Second Place
Third Place
The Grand Prize is awarded to the team whose project demonstrates exceptional innovation, functionality, and overall excellence. This category encompasses projects that excel in various aspects, including creativity, technical complexity, impact, and execution. It recognizes the team that has pushed the boundaries of what is possible in 36 hours and built something incredible.
1st: $12,000
2nd: $8,000
3rd: iPhone 17 Pro Max 512 GB (one per team member)
TreeHacks
Most Creative
The Most Creative prize celebrates the team that shows the highest level of originality, imagination, and ingenuity in their project. This category rewards innovation and unconventional thinking, honoring projects that showcase unique approaches to problem-solving or introduce novel concepts and ideas.
Pioneer DJ DDJ-FLX4
TreeHacks
Most Impactful
The Most Impactful prize recognizes the project that has the potential to create the most significant positive change or address a pressing societal issue. Whether through addressing environmental concerns, improving accessibility, or tackling social injustices, among many other possibilities, this category highlights projects that aim to make a tangible difference in the world.
JBL Partybox 110 
TreeHacks
Most Technically Complex
The Most Technically Complex prize is awarded to the team that exhibits outstanding technical skill, sophistication, and complexity in their project. This category celebrates projects that push the boundaries of technological capabilities, demonstrating mastery in areas such as algorithms, data structures, machine learning, or other advanced technologies.
 DJI Flip
TreeHacks
Best Hardware Hack
The Best Hardware Hack prize honors the team that demonstrates excellence in integrating hardware components into their project. From IoT devices to robotics, this category celebrates projects that leverage physical computing elements to create innovative solutions and interactive experiences.
To be announced‚Ä¶
TreeHacks
Best Beginner Hack
The Best Beginner Hack prize recognizes the outstanding achievement of a team with limited prior experience in coding or hackathons. This category celebrates the journey of learning and discovery, rewarding teams that demonstrate impressive creativity, effort, and progress in their first hackathon endeavor.
Lego Sets (valued at ~$100 each)


TreeHacks 2026 Sponsor Tracks & Challenges

Track Prizes

Sponsor
Name
Description
Prize
OpenAI
Artificial Intelligence Track
Awarded to the top three teams that use OpenAI API most creatively.
1st Place:
 Lunch with OpenAI engineers at the office + 1 year of ChatGPT Pro

2nd Place:
1 year of ChatGPT Pro

3rd Place:
OpenAI swag
Google
Cloud AI Track


1st Place:
Pixel 10 Phones and Pixel Buds (5 Max per team) + $1000 Google Cloud credits

2nd Place:
Pixel Tablets (5 Max per team) + $1000 Google Cloud credits

3rd Place:
Pixel Watches (5 Max per team) + $1000 Google Cloud credits

NVIDIA
Edge AI Track


1st Place:
 1 DGX Spark, 2 $450 Brev Credit vouchers, 2 Jetson Orin Nano Supers, 4 NVIDIA hats
2nd Place:
 1 DGX Spark, 2 $300 Brev Credit vouchers, 1 Jetson Orin Nano Supers, 4 NVIDIA hats
3rd Place:
 4 $200 Brev Credit vouchers, 1 Jetson Orin Nano Super, 4 NVIDIA hats
Zoom
Education Track


 1st Place
$1,000 cash ($250 Amazon GC √ó4)
Meta Ray-Ban Smart Glasses √ó4
Marine Layer Zoom Hoodies √ó4


 2nd Place
Apple AirPods x 4
Zoom Portland Gear Cascade Backpack √ó4


 3rd Place
Sony Noise Cancellation Headphones x 4
Zoom Ocean Bottle √ó4


OpenEvidence
Healthcare Track


$4,000 + Interview Opportunity with OpenEvidence
Anthropic
Human Flourishing Track
This track challenges hackers to showcase how AI can make life better. We want you to see what's possible when technology serves human potential.
1st Place:
4 tungsten cubes 

2nd Place:
1 year of Claude Pro 

3rd Place:
6 months of Claude Pro
Modal
Inference Track
Modal is AI infrastructure developers love, used by companies like Ramp, Suno and Lovable. With flexible GPU compute, code sandboxes, and storage, you can use Modal to run inference or train coding agents, voice agents and more. For the Inference Track, we‚Äôre looking for ambitious applications running inference on Modal to solve a real-world problem.
Inference Track Grand Prize:
$5K in Modal Credits per person, paid visit (flight & hotel) to SF or NY Office with lunch with Modal team,. 

Inference Track Runner Up Prize: 
$1K in Modal credits, airpods for each team member.
Stanford Ecopreneurship


Sustainability: Best solves the user's pain point of a provided challenge
CHALLENGE DOC:

https://docs.google.com/spreadsheets/d/13RBGKPF63ZBhhA8e6FyIb39C7jnnLaCpFkcBVoLHgq8/edit?gid=0#gid=0


$1,500 Cash & feature in Ecopreneurship article
Sustainability: Best prototyping process
$1,500 Cash & feature in Ecopreneurship article
Sustainability: Best incorporation of broader context (e.g. regulatory, competitive landscape) to improve venture viability
$1,500 Cash & feature in Ecopreneurship article
Y Combinator
Build an Iconic YC Company with AI
What if you could rebuild Airbnb, Dropbox, Reddit, or PagerDuty‚Äîbut as if it were born in 2026 with AI at its core? YC is challenging you to do exactly that. The Prompt Pick a YC company from before 2022 (i.e. from before ChatGPT came out), and build an AI-native MVP that reimagines or disrupts it for the world we live in now. This isn‚Äôt about copying the original‚Äîthis is about asking: ‚ÄúIf that company were founded today, what would it look like with AI in the driver‚Äôs seat?‚Äù What to Submit By the deadline, submit the following: A working MVP: Ideally deployed (e.g., Vercel, Replit, Hugging Face Spaces, etc.). 1-2 min Loom video discussing your idea Share your Github with sdhu. Make sure to include a README that has a couple paragraphs describing. Optional: A quick demo video or link to user feedback/test results.
Inspiration:
Start with this list of top YC companies for your target. (https://www.ycombinator.com/companies)
You can also browse our Requests for Startups (RFS) for recent themes we like: Full-stack AI companies AI product management AI-first developer tools Agents, copilots, and assistants (https://www.ycombinator.com/rfs)
1st Place:
Guaranteed YC interview

2nd Place:
Guaranteed YC Office Hours

3rd Place:
Guaranteed YC Office Hours


Sponsor Challenges

Sponsor
Name
Description
Prize
Modal
Sandbox Challenge
 Run AI-generated code in dynamically defined sandboxes. Instantly scale to 50,000+ concurrent sessions. Sandboxes are used by Lovable and Scale AI to run AI-generated web apps, evals, RL environments, and MCP servers. For this challenge, we‚Äôre looking for the best use of sandboxes to build a company.
Sandbox Challenge Grand Prize: 
$5K in Modal Credits per person, paid visit (flight & hotel) to SF or NY Office with lunch with Modal team. 

Sandbox Challenge Runner Up Prize: 
$1K in Modal credits, airpods for each team member.
OpenEvidence
Best Use of Clinical Information
Vast amounts of clinical information already exist‚Äîbut value comes from how it‚Äôs used. This award goes to the project that most creatively and effectively converts existing clinical data into a product that improves understanding, decision-making, or care delivery.
4x Apple Watches
Anthropic
Best Use of Claude Agent SDK
Create an autonomous AI application that tackles real problems.
$2,500 in Claude Developer Platform credits
Zoom x Render
Best use of Zoom APIs + Render:
Best use of Zoom APIs + Render:
Bose Headphones x 4 Zoom Ocean Bottle x 4$2000 Render Credits
NVIDIA
Open Models Hit Different on DGX Spark
Build a multi-agent solution or system with NVIDIA open models
Jetson Orin Nano Super
Neo
Most Likely to Become a Product
We‚Äôre looking for strong product intuition, rooted in real problems and real human behavior. Team: Founders who would seriously consider committing long-term. 
Airfare and accommodations for your team to join a Neo retreat alongside Neo scholars, startup founders, and experienced mentors.
Human Capital
Human Capital Fellowship Prize
Awarded to a team of exceptional engineers solving a big, ambitious problem and eager to build their vision for the long term.
Acceptance to Human Capital Fellowship, $50k equity-free check per team member (up to $200k total) 

HC Fellowship is a program for exceptional engineers ready to tackle massive problems and build generational companies. Each team member will receive a $50k equity-free check (up to $200k total per team), hundreds of potential customer calls scheduled on your behalf, and 24/7 access to our community space for builders in our San Francisco office. Learn more here: https://human.capital/hc-fellowship
Greylock
Best multi-turn agent
Award for the best hack that includes an agent that reasons about feedback to dynamically complete complex, multi-step tasks
Courtside tickets to Warriors game ($10k value)
Office hours with Greylock Partners
Visa
The Generative Edge: Future of Commerce
Reimagine shopping ‚Äî use generative AI to craft smarter + effortless commerce
$10,000 total, awarded to one winning team (up to four participants).
For teams with multiple members, the prize will be distributed among team members at the team‚Äôs discretion.
Fetch.ai
Build, launch and monetise AI Agents on Agentverse that turn user intent into real outcomes.
ü§ñ What are AI Agents? They are autonomous pieces of software that can understand goals, make decisions, and take actions on behalf of users. üöÄ Your Mission Design a multi-agent workflow that takes natural language goals, breaks them into multi-step plans, and adapts in real time to ensure success - while including built-in monetization so you can charge for usage, outcomes or features.   Use any agentic framework like Langgraph, CrewAI, ADK, etc.  of your choice to bring your idea to life.   Deploy your agents to Agentverse and implement the Chat & Payment Protocol to support direct ASI:One interactions and built-in monetization.   You can also create custom applications that use agents in the backend, delivering innovative user experiences and unlocking new monetization opportunities.   üåç Inspiration Productivity ‚Äì Tools that make daily tasks faster and smoother. Automations for schoolwork, small businesses, or niche workflows like CRM updates, email handling, or social media coordination.   Finance ‚Äì Agents that improve personal or corporate finances. From expense trackers to credit assessment or portfolio optimization, anything that helps users save, invest, or manage money.   Education ‚Äì Agents that help people learn, stay updated, and understand complex topics. Think interactive study aids, AI explainers, or research companions.   Wildcard ‚Äì Got an idea that doesn‚Äôt fit neatly into the above? Go for it. As long as it uses the Fetch.ai stack and delivers real value, it belongs here.
Best Overall AI Agent Solution - $2500

Best Multi-Agent Workflow - $1500

Best Monetised Agent - $1000
Runpod
Best use of Flash 
Build a project that deploys at least one Runpod Serverless GPU endpoint using Flash and demonstrates real functionality. Bonus for clear documentation showing how to deploy and run.
1st Place: 
200 Runpod credits per team member (up to 4). 

2nd Place: 
100 Runpod credits per team member (up to 4). 

3rd Place:
50 Runpod credits per team member (up to 4).
Elastic
Best end-to-end Agentic system on Elasticsearch
Depth and creativity of the Elasticsearch implementation 

Use of JINA for embeddings 

Use of Elastic Agent Builder and Workflows Use of Elastic Cloud
1st Place:
$2,000 (split across team members)

2nd Place:
$1,000 (split across team members)
Cloudflare
Best Use of Cloudflare Developer Platform
You might know Cloudflare from just stopping the bad guys with DDoS protection, security, and global scale. But there's much more than that. There is an entire developer platform, including primitives that you can use to build whatever you build during this hackathon. Show us what you got!
$250K Cloudflare credits + Cloudflare swag bag for each team member.
HeyGen
Best creation with HeyGen Avatar API 
The goal of this challenge is to push the  boundaries of real-time streaming and AI-driven video. Use the HeyGen Avatar API to create a seamless, low-latency interface that brings a digital persona to life. We are looking for clever integrations that combine HeyGen‚Äôs high-fidelity "A-roll" video with LLMs, unique UI/UX, or third-party data sources
4 Airpod Pros 3, 1 year of HeyGen Creator license, guaranteed onsite interviews for FTE or intern roles
The Interaction Company of California

Build with Poke


Challenges:
1. Most Useful
2. Most Technically Impressive
3. Most Viral 
Challenge 1: iPhone Air 
Challenge 2: iPhone 17 Pro
Challenge 3: iPhone Air
Decagon
Best Conversation Assistant
At Decagon, we build AI agents that can hold natural, useful conversations- so for this challenge, we‚Äôre looking for the most impressive conversational assistant experience. Create an assistant that feels humanlike and conversational, showcasing its ability to take turns, understand context, and provide meaningful help to its user(s) whether it‚Äôs answering questions, guiding a task, or improving someone‚Äôs workflow.
Nintendo Switch 2 
Mario Kart World Bundle Guaranteed onsite interviews for internship
Browserbase
Best Web Automation with Stagehand
Use Stagehand, an AI browser automation framework built by Browserbase, to automate anything on the web.
$1,000
Zingage
Best Voice AI for Healthcare
Healthcare runs on phone calls‚Äìbut too often, critical information gets lost, delayed, or mishandled. A single live call can signal a missed visit, a sudden health concern, or a scheduling conflict that requires immediate action.

Build a real-time Voice AI for Healthcare that listens during live calls, extracts clinically and operationally relevant information, and takes action. Your system might detect safety or medication red flags, generate structured clinical summaries, initiate automated care-repair workflows... the sky is your limit.
Airpods Max + fast-track to superday with Zingage
Graphite
Most Likely to get Acquired by a Sponsor
Graphite ü§ù Cursor. Sometimes the best ideas don‚Äôt just win prizes ‚Äî they win buyers.  This challenge is about building something with real, tangible value for companies: a product, workflow, system, or prototype that clearly solves a meaningful problem and could plausibly live inside an existing business.  Think less ‚Äúweekend demo,‚Äù more ‚Äúthis would actually move metrics.‚Äù Bonus points if your project improves developer productivity or collaboration.
OB‚Äì4 black bluetooth speaker


Warp
Best Use of Warp Agents


Keychron Mechanical Keyboard for each team member
Suno
Best Musical Hack


1st Place:
Guaranteed onsite/ final interview for an internship or part/full time position with Suno + 1 year Suno Premier subscription. 

2nd Place:
Guaranteed onsite/ final interview for an internship or part/full time position with Suno + 1 year Suno Pro subscription. 


Bright Data
Bright Data: Best AI-Powered Web Data Hack


Bright Data: Best AI-Powered Web Data Hack ($500 Cash + $1.5k Credits [1st] & $350 Cash + $1K Credits [2nd] & $250 Cash + $500 Credits [3rd])
$1,100 in cash, $3,000 in credits

 For 3 winners
Vercel
Best Use of Vercel/Best Deployed on Vercel
Awarded to the team that best leverages Vercel to build, deploy, and scale a production-ready web application. Judges will consider performance, developer experience, and creative use of the Vercel platform.
2k cash prize + $2.4k in Pro-level access credits ($100/month for 4 winners, access for 6 months.)
Perplexity
Best Use of Perplexity's Sonar API


Build something extraordinary with Perplexity‚Äôs Sonar API ‚Äî the most powerful research and reasoning engine behind Perplexity. We‚Äôre looking for the most the project that best demonstrates innovative use, technical excellence, and clear real-world value.
$500 per team member and trip to Perplexity office


More coming soon‚Ä¶.









Okay.

Now we can be surgical.

If you build an AI-powered GitHub security + vulnerability reasoning system, here is exactly where you can realistically compete ‚Äî and where you should strategically apply.

I‚Äôll divide this into:

üèÜ High-probability wins

üéØ Strategic stretch targets

‚ùå Not worth targeting

üî• How to shape the project to maximize prize surface area

üèÜ High-Probability Fits
1Ô∏è‚É£ OpenAI ‚Äì Artificial Intelligence Track

‚ÄúTop three teams that use OpenAI API most creatively.‚Äù

This is a perfect fit if:

You use GPT-4o / reasoning models

Multi-file vulnerability reasoning

Exploit-chain generation

Patch diff generation

Security reasoning prompts

Judges here care about:

Creative API usage

Clever prompt orchestration

Agentic reasoning

If you build:

A repo-aware multi-step reasoning agent that models exploit chains

This is competitive.

2Ô∏è‚É£ Modal ‚Äì Inference Track

This one is very strong for you.

If you:

Run repo embedding on Modal GPUs

Do scalable inference

Use Modal for structured pipeline

Optimize latency

Show cost-efficient scanning

You can pitch:

‚ÄúWe built a scalable AI security engineer running entirely on Modal.‚Äù

That hits their exact messaging.

And the prize is serious:

$5K Modal credits per person

Paid visit

Lunch with team

This is real infra builder territory.

Given your systems background ‚Üí strong fit.

3Ô∏è‚É£ Greylock ‚Äì Best Multi-Turn Agent

This is VERY strong if you design it properly.

They want:

Agent that reasons about feedback to dynamically complete complex, multi-step tasks

Security scanning is naturally multi-turn.

You can build:

Agent analyzes repo

Finds vulnerability

Simulates exploit

Refines reasoning

Proposes patch

Verifies patch fixes exploit

Iterates

That‚Äôs textbook multi-turn agent reasoning.

This might actually be your best sponsor challenge.

Courtside Warriors tickets + Greylock office hours is not small.

4Ô∏è‚É£ YC ‚Äì Build an Iconic YC Company with AI

Now this is interesting.

Reframe your project as:

‚ÄúRebuilding GitHub Security for the AI era.‚Äù

Pick:

PagerDuty

GitHub itself

Snyk

Datadog

New Relic

And say:

If Snyk were built today with AI-native reasoning instead of static rules‚Ä¶

That fits perfectly.

And:
Guaranteed YC interview is extremely high value.

This is not just a prize ‚Äî it‚Äôs leverage.

5Ô∏è‚É£ Neo ‚Äì Most Likely to Become a Product

This is extremely aligned.

Neo explicitly wants:

Real product intuition

Founders who would commit long-term

An AI security tool:

Real problem

Huge market

Clear buyer (dev teams)

This is one of your strongest fits.

6Ô∏è‚É£ Human Capital Fellowship

This is massive.

$50k equity-free per person.

If you frame it as:

‚ÄúWe‚Äôre building autonomous security infrastructure for the AI-native software era.‚Äù

This absolutely qualifies as:

Massive problem

Generational company angle

This is high risk, high reward ‚Äî but worth applying.

üéØ Strategic Stretch Targets
Elastic ‚Äì Agentic system on Elasticsearch

If you:

Use Elastic

Index repo

Use JINA embeddings

Build RAG pipeline

You could qualify.

But this requires deliberate architecture choice.

Cloudflare ‚Äì Best Use of Developer Platform

If you:

Deploy GitHub webhook scanner on Workers

Use Cloudflare storage

Use R2

Use Durable Objects

You could tailor it to this.

But only if infra is built that way.

Vercel ‚Äì Best deployed on Vercel

If frontend is clean and deployed.

Easy to apply for this one.

Perplexity ‚Äì Sonar API

Not ideal unless you integrate their reasoning engine directly.

‚ùå Not Worth Targeting

Healthcare

Sustainability

Commerce

Education

Voice AI healthcare

Music

Zoom

NVIDIA Edge (unless you do on-device scanning)

Hardware

Stay focused.

üî• Maximum Prize Surface Strategy

You can apply for 10 prizes.

Here‚Äôs an optimized list:

OpenAI AI Track

Modal Inference Track

Greylock Multi-Turn Agent

YC Challenge

Neo Most Likely Product

Human Capital Fellowship

Elastic Agentic System

Cloudflare Dev Platform

Vercel Best Deployment

Most Technically Complex (auto)

Plus:

Grand Prize (auto)

Most Impactful (auto)

Most Creative (auto)

That‚Äôs serious coverage.

üß† How to Architect It to Hit Multiple Tracks

Design it like this:

Core

Multi-turn security reasoning agent

Repo graph modeling

Exploit chain simulation

Patch generation

Infra

Inference on Modal

Repo indexed in Elastic

Webhook deployed on Vercel

Cloudflare for edge routing

Now suddenly:
You qualify for 6+ infra challenges naturally.

üí° Strategic Advice

Security AI tools are common.

To stand out:

Don‚Äôt build:

‚ÄúAI that summarizes vulnerabilities.‚Äù

Build:

‚ÄúAutonomous security engineer that reasons about attack surfaces.‚Äù

Key demo moment:

You show:

‚ÄúHere is the exploit chain across 3 files.‚Äù
‚ÄúHere is the attack payload.‚Äù
‚ÄúHere is the patch.‚Äù
‚ÄúHere is proof the exploit no longer works.‚Äù

If you do that clearly, you compete.

üö® Hard Truth

This project only wins if:

It looks polished

The demo is crisp

You explain clearly

You don‚Äôt overscope

The biggest hackathon mistake is:
Trying to build too much infra.

You need:

Clean repo ingestion

Smart chunking

Focused reasoning loop

Clean UI

Strong demo narrative

If you want next step, we can:

Narrow the scope to something achievable in 36 hours

Design exact system architecture

Decide whether to optimize for YC vs Greylock vs OpenAI

Or pressure-test whether there‚Äôs an even stronger idea given this prize list

What‚Äôs your instinct ‚Äî maximize prizes, or maximize long-term startup angle?

should we do it as a chrome extension? that you can just do it in your browser on any repo you're already on too

Yes ‚Äî a Chrome extension is a strong choice for this if you use it to make the demo effortless.

When a Chrome extension is the right move

Do it as an extension if you want:

1-click UX: ‚ÄúScan this repo‚Äù button right on GitHub

A wow demo: judges see it working on a real repo page instantly

Zero ‚Äúpaste URL / sign in / go to our site‚Äù friction

A clean story: ‚ÄúSecurity copilot lives where developers already are.‚Äù

This also makes you more credible for:

Neo (product)

YC challenge

Graphite ‚Äúacquired by sponsor‚Äù (dev workflow tool)

When it‚Äôs not the right move

Avoid extension if:

You‚Äôll burn 8‚Äì12 hours fighting Chrome extension plumbing + OAuth + CORS

You can‚Äôt deliver a clean backend anyway (extension alone can‚Äôt do heavy analysis)

You want to optimize for Modal Inference Track and need a polished compute pipeline more than UI flash

In practice: extension UI + backend compute is best.

Recommended architecture (hackathon-safe)

Extension = UI + context capture. Backend = brains.

Extension does:

Detect repo owner/name + current branch

Pull:

package.json, requirements.txt, Dockerfile, .github/workflows/*

‚Äúinteresting‚Äù files (auth, config, crypto, request handlers)

Show results panel on GitHub:

Findings list

Exploit chain (if any)

Suggested patch diff

‚ÄúOpen PR‚Äù button (optional stretch)

Backend does:

Fast retrieval over repo (GitHub API)

Chunking + embeddings / indexing

Multi-turn agent reasoning

Generates structured JSON output for the extension UI

This keeps the extension lightweight and prevents you from getting stuck on GitHub rate limits / token issues inside the browser.

Prize implications

Chrome extension helps these a lot:

Neo ‚Äì Most likely to become a product (it feels like a real workflow tool)

YC challenge (AI-native devtool)

Graphite acquired by sponsor (dev productivity + collaboration)

Greylock multi-turn agent (if your backend is an actual agent loop)

It doesn‚Äôt hurt:

OpenAI AI track (they‚Äôll judge the intelligence)

Modal inference track (you can still run all inference on Modal)

Scope that‚Äôs actually doable in 36 hours

If you choose extension, keep it brutally minimal:

MVP (what you should ship)

Chrome extension injected into GitHub repo pages

‚ÄúScan repo‚Äù button

Backend returns:

Top 3 vulnerabilities with evidence snippets

One exploit chain (even if simulated)

Patch suggestion (diff-style text)

UI shows it cleanly

Stretch (only if ahead)

‚ÄúComment on PR‚Äù or ‚ÄúOpen PR with patch‚Äù

Repository-wide call graph

Workflow misconfig detection

Secrets scanning

Key hackathon trick

Do not rely on user OAuth. It‚Äôs a time sink.

Instead:

Use a single team GitHub token on backend (from env var)

Only scan public repos for demo

If judges ask: ‚ÄúPrivate repos coming next.‚Äù

That saves hours.

My recommendation

Yes, do the Chrome extension if your goal is to win product/story/demo awards (Neo/YC/Graphite) and still be competitive elsewhere.

If your goal is purely technical/inference awards: a web app is simpler.
But extension + backend is the best overall hackathon weapon.

If you say ‚Äúyes extension,‚Äù I‚Äôll give you:

A concrete build plan (hour-by-hour)

Folder structure for extension + backend

Minimal API contract (JSON schema)

A demo script that sells it to judges in 60 seconds

should it be like a website then??

Website is the safer default for TreeHacks, and you can still make it feel ‚Äúin-browser on any repo‚Äù without extension pain.

Here‚Äôs the decision rule:

Pick a website if you want to maximize ‚Äúwe will definitely ship‚Äù

Do a website if you want:

fastest path to a polished demo

no Chrome extension boilerplate / permissions / content scripts

easier deploy (Vercel / Render)

easier for sponsor judges to try it instantly

You can still have ‚Äúworks on any repo you‚Äôre on‚Äù via a bookmarklet:

user is on a GitHub repo page

clicks bookmarklet

it opens your site and passes the repo URL

site auto-runs scan

That gives you extension-like UX with ~5% of the hassle.

Pick a Chrome extension if you want maximum ‚Äúwow‚Äù + workflow integration

Extension is worth it only if:

one of you is comfortable with extension dev already

you‚Äôll keep it minimal (just button + side panel)

backend is already solid

What I‚Äôd do for a 36-hour hack

Website + bookmarklet.

It‚Äôs:

high polish

low risk

judges can click once and see results

still feels ‚Äúnative to GitHub‚Äù

Prize alignment (given your list)

Website hits:

OpenAI AI Track

Modal Inference Track

Greylock multi-turn agent

Neo product

YC challenge

Vercel best deployed (easy)

Cloudflare (optional)

Extension mostly adds:

stronger ‚Äúproduct/workflow‚Äù vibe (Neo/Graphite)
‚Ä¶but costs time.

Minimal website flow that sells hard

Landing page: paste GitHub URL

‚ÄúScan‚Äù ‚Üí results in <30‚Äì60s

Results page shows:

Top findings (with file/line + snippet)

Exploit chain diagram (even simple)

Patch diff (copy / apply)

Optional: ‚ÄúGenerate PR‚Äù (stretch)

Concrete recommendation

Do website now, and if you finish early:

add extension wrapper Sunday morning (or just keep bookmarklet)

This is the highest probability of shipping something that wins.

If you tell me what stack you prefer (Next.js vs simple React, and Python FastAPI vs Node), I‚Äôll give you a tight architecture + repo structure + API schema you can implement fast.

What is a good repo or set of todos to test it on

Good test repos are the ones where (a) there are real, known vulns, (b) the codebase is small enough to scan in a hackathon, and (c) the vuln types are diverse so your tool can show ‚Äúreasoning,‚Äù not just pattern matching.

Best ‚Äúone repo‚Äù to start with

OWASP Juice Shop (Node/JS)
Great for: auth flaws, injection-ish issues, insecure logic, lots of well-known intentionally vulnerable patterns.
Why it‚Äôs good: judges recognize it; you can demo fast.

Great intentionally-vulnerable training set (pick 2‚Äì4)
Web apps

WebGoat (Java)
Great for: SQLi, XSS, auth/session issues, access control.

DVWA (PHP)
Great for: classic web vulns; very fast wins.

RailsGoat (Ruby on Rails)
Great for: Rails-specific mistakes + auth/access control.

Node-specific (good if your scanner is JS-first)

Damn Vulnerable Node Application (DVNA)
Great for: modern Node/Express mistakes, auth, injection, misconfig.

Microservice-style (good for ‚Äúattack chain‚Äù demos)

OWASP NodeGoat (Node/Express)
Great for: showing flow across routes/controllers ‚Üí DB ‚Üí auth.

Repos that are not intentionally vulnerable, but good for ‚Äúrealistic‚Äù scanning

Pick something popular-ish and medium sized so you can show ‚Äúwe found 1‚Äì2 real issues + risky patterns,‚Äù without needing a perfect exploit:

any small FastAPI demo app, Express demo, or Next.js starter with auth + DB
(These are good for detecting risky patterns, secrets, bad configs, etc.)

A tight ‚Äútest todo list‚Äù for your scanner (what to verify it can do)

Start with these checks in this order (each one is demo-friendly):

Secrets & keys

.env, hardcoded API keys, AWS tokens, private keys, JWT secrets
Output: exact file path + redacted snippet + ‚Äúwhat to rotate‚Äù.

Dependency risk

package-lock.json, requirements.txt, pom.xml, Gemfile.lock
Output: list top CVEs + whether it‚Äôs reachable (if you can).

Auth / access control logic

routes that look protected but aren‚Äôt
Output: ‚Äúendpoint X lacks auth middleware; here‚Äôs the call path‚Äù.

Injection primitives

SQL queries built from strings

shell execution (exec, spawn, subprocess) with user input
Output: ‚Äúsource ‚Üí sink‚Äù chain across files.

SSRF / unsafe URL fetch

requests.get(user_url) / fetch(user_url)
Output: why it‚Äôs exploitable + suggested allowlist / URL parsing fix.

GitHub Actions / CI misconfigs

.github/workflows/* risky pull_request_target, unpinned actions, curl | bash
Output: ‚Äúsupply chain risk‚Äù findings.

If your tool can do (3) or (4) with a real multi-file chain, that‚Äôs the ‚ÄúGreylock multi-turn agent‚Äù / ‚ÄúMost technically complex‚Äù moment.

How to structure your demo

Use 2 repos:

Juice Shop / NodeGoat / DVNA ‚Üí guaranteed vulnerabilities (makes your tool look smart)

A ‚Äúnormal‚Äù small repo ‚Üí shows real-world usefulness (makes it look like a product)

Quick check so I tailor this right: Maksym or Veronika? (Also: are you building the scanner JS-first, or language-agnostic?)

summarize the entire idea pls

Core idea (one paragraph):

Build an AI security copilot for GitHub repositories ‚Äî a web app (optionally later a browser extension) that analyzes any public repo and behaves like an automated red-team engineer. A user pastes a repo URL, the system scans the codebase, reasons across multiple files using an LLM agent, identifies real security vulnerabilities, explains the exploit chain (how an attacker would actually abuse it), and generates a concrete patch or fix. The goal is not static linting, but AI reasoning about attack surfaces.

What the product does

User flow:

Paste GitHub repo link

Click Scan

System analyzes repo

Returns:

üî¥ Top vulnerabilities

üîó Attack/exploit chain across files

üìç Evidence (file + line snippets)

üõ† Suggested patch (diff-style fix)

(optional) PR-ready fix

What makes it different

Not:

regex scanners

CVE lookup tools

dependency audit wrappers

Instead:

builds a structural understanding of the repo

traces data flow (input ‚Üí processing ‚Üí dangerous sink)

uses a multi-turn AI agent to reason like a security engineer

explains why something is exploitable

Think:

‚ÄúCopilot, but for security review.‚Äù

High-level architecture

Frontend (website):

paste repo ‚Üí show results dashboard

Backend:

Pull repo via GitHub API

Select important files (auth, routes, configs, workflows)

Chunk + index code

AI agent loop:

hypothesize vulnerabilities

verify evidence

build exploit chain

propose fix

Return structured findings

Inference runs on cloud GPUs (Modal / Runpod).

Demo story (what judges see)

‚ÄúHere‚Äôs a real repo.‚Äù

‚Üí click scan
‚Üí AI finds auth flaw across 3 files
‚Üí shows attacker path
‚Üí generates patch

Clear, fast, understandable.

Why it‚Äôs compelling

Huge real-world problem (software security)

Feels like a real startup product

Strong AI + systems angle

Works live on real code

Easy for judges to grasp in 30 seconds

One-line pitch

An autonomous AI security engineer that reviews any GitHub repo and finds real exploit paths ‚Äî not just warnings.